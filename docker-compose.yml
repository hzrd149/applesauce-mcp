services:
  # Ollama service for embeddings
  ollama:
    image: ollama/ollama:latest
    container_name: applesauce-ollama
    volumes:
      # Persist Ollama models between restarts
      - ollama_data:/root/.ollama
    # ports:
    #   - "11434:11434"
    restart: unless-stopped

  # MCP server
  mcp:
    build: .
    container_name: applesauce-mcp
    depends_on:
      - ollama
    environment:
      # Embeddings provider configuration
      - EMBEDDING_PROVIDER=ollama # or "openai" for OpenAI-compatible providers
      - EMBEDDING_MODEL=nomic-embed-text:v1.5

      # Ollama configuration (when EMBEDDING_PROVIDER=ollama)
      - OLLAMA_HOST=http://ollama:11434

      # OpenAI-compatible configuration (when EMBEDDING_PROVIDER=openai)
      # Uncomment and set these when using OpenAI, OpenRouter, etc.
      # - OPENAI_API_KEY=sk-your-api-key-here
      # - OPENAI_BASE_URL=https://api.openai.com/v1

      # Data paths (defaults set in Dockerfile, can override here)
      # - APPLESAUCE_REPO_PATH=/data/applesauce
      # - APPLESAUCE_DB_PATH=/data
    volumes:
      # Persist applesauce repo and LanceDB databases
      - mcp_data:/data
    ports:
      - "3000:3000"
    restart: unless-stopped

volumes:
  # Named volumes for persistence
  ollama_data:
    name: applesauce_ollama_data
  mcp_data:
    name: applesauce_mcp_data
