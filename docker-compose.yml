services:
  # Ollama service for embeddings
  ollama:
    image: ollama/ollama:latest
    container_name: applesauce-ollama
    volumes:
      # Persist Ollama models between restarts
      - ollama_data:/root/.ollama
    # ports:
    #   - "11434:11434"
    restart: unless-stopped

  # MCP server
  mcp:
    build: .
    container_name: applesauce-mcp
    depends_on:
      - ollama
    environment:
      # Embeddings provider configuration
      - EMBEDDING_PROVIDER=ollama # or "openai" for OpenAI-compatible providers
      - EMBEDDING_MODEL=nomic-embed-text:v1.5

      # Ollama configuration (when EMBEDDING_PROVIDER=ollama)
      - OLLAMA_HOST=http://ollama:11434

      # OpenAI-compatible configuration (when EMBEDDING_PROVIDER=openai)
      # Uncomment and set these when using OpenAI, OpenRouter, etc.
      # - OPENAI_API_KEY=sk-your-api-key-here
      # - OPENAI_BASE_URL=https://api.openai.com/v1
    volumes:
      # Persist LanceDB data (applesauce repo is pre-cloned at /opt/applesauce)
      - ./data:/app/data
    ports:
      - "3000:3000"
    restart: unless-stopped

volumes:
  # Named volumes for persistence
  ollama_data:
    name: applesauce_ollama_data
